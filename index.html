
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>Autonomio Deep Learning Workbench User Manual</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .cd {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .nl {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[&quot;python&quot;]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="toc-wrapper">
      <img src="images/logo.png" class="logo" alt="Logo" />
        <div class="lang-selector">
              <a href="#" data-language-name="python">python</a>
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <div id="toc" class="toc-list-h1">
          <li>
            <a href="#introduction" class="toc-h1 toc-link" data-title="Introduction">Introduction</a>
          </li>
          <li>
            <a href="#1-minute-pipepline" class="toc-h1 toc-link" data-title="1-Minute Pipepline">1-Minute Pipepline</a>
          </li>
          <li>
            <a href="#installation" class="toc-h1 toc-link" data-title="Installation">Installation</a>
          </li>
          <li>
            <a href="#training-neural-network" class="toc-h1 toc-link" data-title="Training Neural Network">Training Neural Network</a>
          </li>
          <li>
            <a href="#commands" class="toc-h1 toc-link" data-title="Commands">Commands</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#train" class="toc-h2 toc-link" data-title="Commands">Train</a>
                  </li>
                  <li>
                    <a href="#predictor" class="toc-h2 toc-link" data-title="Commands">Predictor</a>
                  </li>
                  <li>
                    <a href="#wrangler" class="toc-h2 toc-link" data-title="Commands">Wrangler</a>
                  </li>
                  <li>
                    <a href="#hyperscan" class="toc-h2 toc-link" data-title="Commands">Hyperscan</a>
                  </li>
                  <li>
                    <a href="#data" class="toc-h2 toc-link" data-title="Commands">Data</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#examples" class="toc-h1 toc-link" data-title="Examples">Examples</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#prepare-and-train" class="toc-h2 toc-link" data-title="Examples">Prepare and Train</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#shapes" class="toc-h1 toc-link" data-title="Shapes">Shapes</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#funnel" class="toc-h2 toc-link" data-title="Shapes">Funnel</a>
                  </li>
                  <li>
                    <a href="#long-funnel" class="toc-h2 toc-link" data-title="Shapes">Long Funnel</a>
                  </li>
                  <li>
                    <a href="#rhombus" class="toc-h2 toc-link" data-title="Shapes">Rhombus</a>
                  </li>
                  <li>
                    <a href="#diamond" class="toc-h2 toc-link" data-title="Shapes">Diamond</a>
                  </li>
                  <li>
                    <a href="#hexagon" class="toc-h2 toc-link" data-title="Shapes">Hexagon</a>
                  </li>
                  <li>
                    <a href="#brick" class="toc-h2 toc-link" data-title="Shapes">Brick</a>
                  </li>
                  <li>
                    <a href="#triangle" class="toc-h2 toc-link" data-title="Shapes">Triangle</a>
                  </li>
                  <li>
                    <a href="#stairs" class="toc-h2 toc-link" data-title="Shapes">Stairs</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#language-processing" class="toc-h1 toc-link" data-title="Language Processing">Language Processing</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#unstructed-data" class="toc-h2 toc-link" data-title="Language Processing">Unstructed Data</a>
                  </li>
                  <li>
                    <a href="#language-support" class="toc-h2 toc-link" data-title="Language Processing">Language support</a>
                  </li>
                  <li>
                    <a href="#adding-new-languages" class="toc-h2 toc-link" data-title="Language Processing">Adding new languages</a>
                  </li>
              </ul>
          </li>
      </div>
        <ul class="toc-footer">
            <li><a href='https://github.com/autonomio/core-module'>Autonomio on Github</a></li>
            <li><a href='https://github.com/autonomio/core-module#fork-destination-box'>For Autonomio</a></li>
            <li><a href='http://autonom.io'>Autonomio Website</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id='introduction'>Introduction</h1>
<p>Autonomio provides a high-level abstraction layer to building, configuring and optimizing neural networks and then using the trained models to make predictions in any environment. Unlike with other similar solutions, there is no need for signing up, API keys, cloud instances, or GPUs, and you have 100% control over the model. A typical installation takes a minute, and training a model not more than few minutes including data transformation from raw dataset with even thousands of columns, open text, and unstructured labels. Nothing is pre-trained, and only you have access to your data and predictions. There is no commercial entity behind Autonomio, but a non-profit research Foundation.</p>

<p>This document covers the functionality of Autonomio. If you&#39;re looking for a high level overview of the capabilities, you might find the <a href="http://autonom.io">Autonomio website</a> more useful. </p>
<h1 id='1-minute-pipepline'>1-Minute Pipepline</h1>
<blockquote>
<p>To train a model use this code</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="c"># do the python imports </span>
<span class="kn">from</span> <span class="nn">autonomio.commands</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">wrangler</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">predictor</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c"># import the data from csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="s">'medicare_10k.csv'</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'file'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="c"># preprocess the data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">wrangler</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="s">'z'</span><span class="p">)</span>

<span class="c"># train a neural net</span>
<span class="n">train</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">17</span><span class="p">],</span><span class="s">'z'</span><span class="p">,</span><span class="n">df</span><span class="p">,</span><span class="n">epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s">'logcosh'</span><span class="p">,</span><span class="n">flatten</span><span class="o">=</span><span class="s">'median'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>NOTE: list of column index can be used with 3 or more columns. Using two integers will be considered a range of columns.</p>
</blockquote>

<p>Autonomio is very easy to use and it&#39;s very easy to memorize the namespace which is just 4 commands and less than 40 arguments combined. Namespace memorization is one of the key differences between advanced and beginner users. Whereas Autonomio helps lower skill level practitioners to dramatically improve their capability, advanced practitioners enjoy significant productivity gains and headache reduction.</p>

<aside class="notice">
You must replace <code>medicare_10k.csv</code> with your own dataset.
</aside>
<h1 id='installation'>Installation</h1>
<p>The simplest way is to get the latest well tested version is to install with pip from the repo directly. This way you get the latest well tested version, with the latest features. </p>

<p><code>pip install git+https://github.com/autonomio/core-module.git</code></p>
<h1 id='training-neural-network'>Training Neural Network</h1>
<blockquote>
<p>A typical use of the training function for - you guessed it - training a neural network. </p>
</blockquote>
<pre class="highlight python tab-python"><code>
<span class="n">train</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">],</span><span class="s">'Survived'</span><span class="p">,</span><span class="n">df</span><span class="p">,</span>
                        <span class="n">flatten</span><span class="o">=</span><span class="s">'none'</span><span class="p">,</span>
                        <span class="n">epoch</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="s">'logcosh'</span><span class="p">,</span>
                        <span class="n">activation</span><span class="o">=</span><span class="s">'elu'</span><span class="p">,</span>
                        <span class="n">layers</span><span class="o">=</span><span class="n">layer</span><span class="p">,</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre>
<p>Autonomio provides a very high level abstraction layer to several deep learning models:</p>

<ul>
<li>Multi Layer Perceptors (MLP)</li>
<li>LSTM</li>
<li>Regression</li>
</ul>

<p>These are all accessed through the train() command. </p>
<h1 id='commands'>Commands</h1><h2 id='train'>Train</h2>
<ul>
<li>loss</li>
<li>optimization</li>
<li>activation </li>
<li>shape</li>
<li>layers (even thousands of layers)</li>
<li>dropout rate</li>
<li>batch_size</li>
</ul>
<h3 id='data-ingestion'>Data Ingestion</h3>
<p>Compared to TensorFlow, Keras, scikit learn and other common libraries, Autonomio provides a highly convinient data ingestion function. </p>

<ul>
<li>Automatically through train()</li>
<li>Configured throgh train()</li>
<li>Using the wrangler() utility</li>
</ul>
<pre class="highlight python tab-python"><code><span class="c"># a single column where data is string</span>
<span class="n">train</span><span class="p">(</span><span class="s">'text'</span> <span class="p">,</span><span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 

<span class="c"># a single column by index</span>
<span class="n">train</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 

<span class="c"># a single column by label</span>
<span class="n">train</span><span class="p">([</span><span class="s">'quality_score'</span><span class="p">],</span> <span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 

<span class="c"># a range of column index</span>
<span class="n">train</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 

<span class="c"># set of column labels</span>
<span class="n">train</span><span class="p">([</span><span class="s">'quality_score'</span><span class="p">,</span> <span class="s">'reach_score'</span><span class="p">],</span> <span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 

<span class="c"># a list of column index</span>
<span class="n">train</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">18</span><span class="p">],</span> <span class="s">'neg'</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> 
</code></pre>
<p>Data can be inputted from a dataframe, or csv, txt, json or msgpack files. All common transformations take place automatically within the train() command.</p>

<ul>
<li>automatic transformation of dependent variables

<ul>
<li>from text to word vectors

<ul>
<li>from text labels to integers </li>
</ul></li>
</ul></li>
<li>automatic transformation of outcome variable

<ul>
<li>from continuous to categorical

<ul>
<li>based on mean</li>
<li>based on median </li>
<li>based on quantiles </li>
<li>based on ge </li>
</ul></li>
<li>from multi-category to binary

<ul>
<li>string values</li>
<li>numeric values </li>
</ul></li>
</ul></li>
</ul>

<p>Generally speaking, multilayer percepton neural nets are strongest in solving classification problems, where the outcome variable is either binary categorical (0 or 1) or multi categorical. This is why there is strong emphasis in Autonomio on making such transformations available within the train() command. </p>
<h4 id='binary-default'>BINARY (default)</h4>
<ul>
<li>X can be text, int, or floating point </li>
<li>Y can be an int, or floating point</li>
</ul>

<p>The default settings are optimized for making a 1 or 0 prediction and for example in the case of predicting sentiment from tweets, Autonomio gives 85% accuracy without any parameter setting for classifying tweets that rank in the most negative 20% according to NLTK Vader sentiment analysis. </p>
<h4 id='categorical'>CATEGORICAL</h4>
<ul>
<li>X can be text, integer </li>
<li>Y can be an integer or text</li>
<li>output layer neurons must match number of categories</li>
<li>change activation_out to something that works with categoricals</li>
</ul>

<p>It&#39;s not a good idea to have too many categories, maybe 10 is pushing it in most cases. </p>
<h3 id='train-query-parameters'>Train Query Parameters</h3>
<table><thead>
<tr>
<th>ARGUMENT</th>
<th>REQUIRED INPUT</th>
<th>DEFAULT</th>
</tr>
</thead><tbody>
<tr>
<td>X</td>
<td>string, int, float</td>
<td>NA</td>
</tr>
<tr>
<td>Y</td>
<td>int,float,categorical</td>
<td>NA</td>
</tr>
<tr>
<td>data</td>
<td>data object</td>
<td>NA</td>
</tr>
<tr>
<td>epoch</td>
<td>int</td>
<td>5</td>
</tr>
<tr>
<td>flatten</td>
<td>string, float</td>
<td>&#39;mean&#39;</td>
</tr>
<tr>
<td>dropout</td>
<td>float</td>
<td>.2</td>
</tr>
<tr>
<td>layers</td>
<td>int (2 through 5</td>
<td>3</td>
</tr>
<tr>
<td>loss</td>
<td>string [Keras_Losses]_</td>
<td>&#39;binary_crossentropy&#39;</td>
</tr>
<tr>
<td>save_model</td>
<td>string</td>
<td>False</td>
</tr>
<tr>
<td>neuron_first</td>
<td>int,float,categorical</td>
<td>300</td>
</tr>
<tr>
<td>neuron_last</td>
<td>data object</td>
<td>1</td>
</tr>
<tr>
<td>batch_size</td>
<td>int</td>
<td>10</td>
</tr>
<tr>
<td>verbose</td>
<td>0,1,2</td>
<td>0</td>
</tr>
<tr>
<td>shape</td>
<td>string</td>
<td>&#39;funnel&#39;</td>
</tr>
<tr>
<td>double_check</td>
<td>True or False</td>
<td>False</td>
</tr>
<tr>
<td>validation</td>
<td>True,False,float(0 to 1)</td>
<td>False</td>
</tr>
</tbody></table>

<p><strong>X</strong> = The input can be indicated in several ways::</p>

<p>&#39;label&#39;   = single column label
[&#39;a&#39;,&#39;b&#39;] = multiple column labels
[1,12]    = a range of columns
[1,2,12]  = columns by index
The data can be multiple dtypes:
&#39;int&#39;     = any integer values
&#39;float&#39;   = any float value
&#39;string&#39;  = raw text or category labels</p>

<p>In case you need to cleanup your data first, you can do it with::</p>

<p>from autonomio.commands import wrangler</p>

<p>wrangler(data,outcome_var)</p>

<p><strong>Y</strong> =  This can be in multiple dtype::</p>

<p>&#39;int&#39;     = any integer values
&#39;float&#39;   = any float value
&#39;string&#39;  = category labels</p>

<p>See more related to prediction variable below in the &#39;flatten&#39; section.</p>

<p><strong>data</strong> =  A pandas dataframe where you have at least one column for &#39;x&#39; depedent variable (predictor) and one column for &#39;y&#39; indepedent variable (prediction).</p>

<p><strong>dims</strong> =  This is selected automatically and is not needed to worry about. NOTE: this needs to be same as x features</p>

<p><strong>epoch</strong> = how many epocs will be run for training. More epochs will take more time.</p>

<p><strong>flatten</strong> = For transforming y (outcome) variable. For example if the y input is continuous but prediction is binary, then a flattening of some sort should be used.</p>

<p>OPTIONS:  &#39;mean&#39;,&#39;median&#39;,&#39;mode&#39;, int, float, &#39;cat_string&#39;, &#39;cat_numeric&#39;, and &#39;none&#39;</p>

<p><strong>dropout</strong> = The fraction of learning that will be &quot;forgotten&quot; on each each learning event.</p>

<p><strong>layers</strong> = The number of dense layers the model will have. Note that each dense layer is followed by a dropout layer.</p>

<p><strong>model</strong> = This is currently not in use. Later we add LSTM and some other model options, then it will be activated.</p>

<p><strong>loss</strong> = The loss to be used with the model. All the Keras losses all available https://keras.io/losses/</p>

<p><strong>optimizer</strong> = The optimizer to use with the model. All the Keras optimizers are all available &gt; https://keras.io/optimizers/</p>

<p><strong>activation</strong> = Activation for the hidden layers (non-output) and all the Keras optimizers are all available &gt; https://keras.io/optimizers/</p>

<p><strong>activation_out</strong> = Same as &#39;activation&#39; (above), but for the output layer only.</p>

<p><strong>save_model</strong> =  An option to save the model configuration, weights and parameters.</p>

<p>OPTIONS:  default is &#39;False&#39;, if &#39;True&#39; model will be saved with default name (&#39;model&#39;) and if string, then the model name will be the string value e.g. &#39;titanic&#39;.</p>

<p><strong>neuron_max</strong> = The maximum number of neurons on any layer.</p>

<p><strong>neuron_last</strong> = How many neurons there are in the last layer.</p>

<p><strong>batch_size</strong> = Changes the number of samples that are propagated through the network at one given point in time. The smaller the batch_size, the longer the training will take.</p>

<p><strong>verbose</strong> = This is set to &#39;0&#39; by default. The other options are &#39;1&#39; and &#39;2&#39; and will change the amount of information you are getting.</p>

<p><strong>shape</strong> = Used for automatically creating a network shape. Currently there are 8 options available: &#39;funnel&#39;, &#39;rhombus&#39;, &#39;long_funnel&#39;, &#39;brick&#39;, &#39;hexagon&#39;, &#39;diamond&#39;, &#39;triangle&#39;, &#39;stairs&#39;. Diagram is provided for each in the &#39;Shape&#39; section. </p>

<p><strong>double_check</strong> = Makes a &#39;manual&#39; check of the results provided by Keras backend and compares the two. This is good when you have doubt with the results.</p>

<p><strong>validation</strong> = Validates in a more robust way than usual train/test split by initially splitting the dataset in half, where the first half becomes train and test, and then the second half becomes validation data set. </p>

<p>OPTIONS: default is &#39;false&#39;, with &#39;true&#39; 50% of data is separated for validation.</p>
<h2 id='predictor'>Predictor</h2><pre class="highlight python tab-python"><code><span class="n">predictor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s">'model.json'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>Add labels to prections</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">test</span><span class="p">(,</span><span class="n">data</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="s">'handle'</span><span class="p">,</span><span class="s">'model.json'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>Add an interactive scatter plot visualization with an y-axis variable::</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">test</span><span class="p">(,</span><span class="n">data</span><span class="p">,</span><span class="s">'handle'</span><span class="p">,</span><span class="s">'model.json'</span><span class="p">,</span><span class="n">y_scatter</span><span class="o">=</span><span class="s">'influence_score'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>To yield the scatter plot, you have to call it specifically</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">test_result</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="s">'handle'</span><span class="p">,</span><span class="s">'model.json'</span><span class="p">,</span><span class="n">y_scatter</span><span class="o">=</span><span class="s">'influence_score'</span><span class="p">)</span>
<span class="n">test_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre>
<p>Once you&#39;ve trained a model with train(), you can use it easily on any dataset through the predictor() command. You could use it in the Jypyter notebook, have it run on a server as part of some other process, or make it part of a website that does something interesting for the user based on their input. Just to name a few examples. Think of a trained neural net model as what is referred to as AI. It&#39;s far more easier to have AIs doing various tasks than most people think.  </p>
<h3 id='test-query-parameters'>Test Query Parameters</h3>
<table><thead>
<tr>
<th>ARGUMENT</th>
<th>REQUIRED INPUT</th>
<th>DEFAULT</th>
</tr>
</thead><tbody>
<tr>
<td>X</td>
<td>variable/s in dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>data</td>
<td>pandas dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>labels</td>
<td>variable/s in dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>saved_model</td>
<td>filename</td>
<td>5</td>
</tr>
<tr>
<td>y_scatter</td>
<td>variable in dataframe</td>
<td>&#39;mean&#39;</td>
</tr>
</tbody></table>
<h2 id='wrangler'>Wrangler</h2>
<p>The wrangler() function introduces &quot;best-of-class&quot; data ingestion capability for maximum convinience of single file preparation. If you have to work with multiple files, handle each file separately and then merge afterwards. Based on the parameter configuration, wrangler() yields a dataframe where one or more of the following may be true: </p>
<pre class="highlight python tab-python"><code>
<span class="kn">from</span> <span class="nn">autonomio.commands</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">wrangler</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">,</span><span class="s">'file'</span><span class="p">)</span>
<span class="n">titanic</span> <span class="o">=</span> <span class="n">wrangler</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">,</span><span class="n">starts_with_col</span><span class="o">=</span><span class="s">'Cabin'</span><span class="p">,</span><span class="n">first_fill_cols</span><span class="o">=</span><span class="s">'Cabin'</span><span class="p">)</span>

</code></pre>
<blockquote>
<p>NOTE: Typical kernel examples on Kaggle show that the same dataset require data scientist 30 to 100 lines of code in order to get to the exactly same result we get to here with a single wrangler() command. </p>
</blockquote>

<ul>
<li>columns are dropped entirely</li>
<li>rows are dropped</li>
<li>unstructured columns are transformed in to categories</li>
<li>unstructured columns are transformed in to word vectors (floats)</li>
<li>NaN values are filled</li>
</ul>

<p><strong>data</strong> = A pandas dataframe that needs to be transformed. </p>

<p><strong>y</strong> = The feature that will be moved as the first column in the dataframe and will not be transformed in anyway. </p>

<p><strong>max_categories</strong> = Accepts an integer value. In columns with string values (automatically detected), if there are more unique values than &#39;max_categories&#39;, then the column will be not categorized and will be dropped instead. Such column could be treated with &#39;vectorize&#39; parameter instead. </p>

<p><strong>starts_with_col</strong> = Accepts a string value. For cases where a column of string values want to be transformed in to categories based on a shared first character in the string. </p>

<p><strong>treshold</strong> = Accepts a floating point value (or 1). Sets the limit at which point a column will be entirely dropped because of two many NaN values. For example .6 means that if more than 60% of column&#39;s values are NaN, the whole column will be dropped. </p>

<p><strong>first_fill_colls</strong> = Access a column name as value. For cases where a given column NaN values are filled first, so that it will not be dropped if it does not meet the &#39;treshold&#39; parameter. This is for cases where some columns want to be retained even they have a high number of NaN values. </p>

<p><strong>fill_with</strong> = A string, integer or float value. The value that is used for filling NaNs. </p>

<p><strong>to_string</strong> = A column name. For the case where a given column may be needed later as a string value, for example a name to be connected with prediction values later. </p>

<p><strong>vectorize</strong> = A column name. Vectorizes the text inputs in to 300 features, each representing a value in the word2vec vector. </p>

<table><thead>
<tr>
<th>ARGUMENT</th>
<th>REQUIRED INPUT</th>
<th>DEFAULT</th>
</tr>
</thead><tbody>
<tr>
<td>data</td>
<td>pandas dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>y</td>
<td>the outcome variable</td>
<td>NA</td>
</tr>
<tr>
<td>max_categories</td>
<td>max number of unique categories</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>starts_with_col</td>
<td>a column in the dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>treshold</td>
<td>a % treshold of NaN values for dropping whole column</td>
<td>.9</td>
</tr>
<tr>
<td>first_fill_cols</td>
<td>a column in the dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>fill_with</td>
<td>a string, integer or float value</td>
<td>0</td>
</tr>
<tr>
<td>to_string</td>
<td>a column in the dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>vectorize</td>
<td>a column in the dataframe with string values*</td>
<td>NA</td>
</tr>
</tbody></table>

<aside class="notice">
* Vectorization could be done to numbers as well, but is not the intended usecase.
</aside>
<h2 id='hyperscan'>Hyperscan</h2>
<p>The hyperscan() function is for scanning through hyperparameter configurations automatically or based on set ranges / lists. Starting a scan is as easy as it would be to run the train() command but instead of trainining a model with a single set of parameters, it does it with multiple configurations. For detailed overview of the parameters, see the section for <a href="#train">train()</a>. The below section will provide an overview of the parameters that are unique to hyperscan(). </p>
<pre class="highlight python tab-python"><code>
<span class="n">result</span> <span class="o">=</span> <span class="n">hyperscan</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> 
                   <span class="s">'i'</span><span class="p">,</span> 
                   <span class="n">diabetes</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
                   <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                   <span class="n">scan_mode</span><span class="o">=</span><span class="s">'selective'</span><span class="p">,</span> 
                   <span class="n">losses</span><span class="o">=</span><span class="s">'logcosh'</span><span class="p">,</span>
                   <span class="n">shapes</span><span class="o">=</span><span class="p">[</span><span class="s">'brick'</span><span class="p">,</span><span class="s">'long_funnel'</span><span class="p">],</span> 
                   <span class="n">optimizers</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span>
                   <span class="n">activations</span><span class="o">=</span><span class="s">'softsign'</span><span class="p">,</span>
                   <span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
                   <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">,</span><span class="mi">20</span><span class="p">])</span>

</code></pre>
<blockquote>
<p>NOTE: Hyperscan is not a solution for optimization of hyperparameters, but a way to automate the most mindless part of model configuration. Currently there are six options for parameters to be scanned:</p>
</blockquote>

<ul>
<li>number of layers</li>
<li>shape of the NN</li>
<li>batch_size</li>
<li>activation</li>
<li>optimizer</li>
<li>loss</li>
</ul>

<p>Each can be scanned in three modes: </p>

<ul>
<li>single value</li>
<li>a list of values</li>
<li>all values (&#39;auto&#39;)</li>
</ul>

<p>In addition &#39;batch_size&#39; and &#39;layers&#39; also support: </p>

<ul>
<li>a range of values</li>
<li>a stepped range of values </li>
</ul>

<p>For full reference, see the section for <a href="#train">train()</a> parameters. </p>

<p><strong>batch_size_step</strong> = An integer. The number of values skipped, for example in a range of 2 to 20, &#39;batch_size_step&#39; value 2 will skip 3,5,7,9...and so on.  </p>

<p><strong>layers_step</strong> = Same as &#39;batch_size_step&#39; above but for layers. </p>

<p><strong>scan_mode</strong> = If set on auto, all possible options will be scanned through. Note that this will take time, even with a powerful machine. In most cases it&#39;s better to use &#39;selective&#39; with reasonable preset values in lists. </p>

<table><thead>
<tr>
<th>ARGUMENT</th>
<th>REQUIRED INPUT</th>
<th>DEFAULT</th>
</tr>
</thead><tbody>
<tr>
<td>x</td>
<td>pandas dataframe</td>
<td>NA</td>
</tr>
<tr>
<td>y</td>
<td>the outcome variable</td>
<td>NA</td>
</tr>
<tr>
<td>data</td>
<td>max number of unique categories</td>
<td>NA</td>
</tr>
<tr>
<td>flatten</td>
<td>a column in the dataframe</td>
<td>&#39;none&#39;</td>
</tr>
<tr>
<td>dropout</td>
<td>an float</td>
<td>0</td>
</tr>
<tr>
<td>batch_sizes</td>
<td>a integer</td>
<td>15</td>
</tr>
<tr>
<td>batch_sizes_step</td>
<td>an integer</td>
<td>1</td>
</tr>
<tr>
<td>layers</td>
<td>an integer</td>
<td>5</td>
</tr>
<tr>
<td>layers_step</td>
<td>an integer</td>
<td>1</td>
</tr>
<tr>
<td>activation_out</td>
<td>single, list or &#39;auto&#39;</td>
<td>&#39;sigmoid&#39;</td>
</tr>
<tr>
<td>neuron_max</td>
<td>an integer</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>scan_mode</td>
<td>&#39;selective&#39; or &#39;auto&#39;</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>losses</td>
<td>single, list or &#39;auto&#39;</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>optimizers</td>
<td>single, list or &#39;auto&#39;</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>activations</td>
<td>single, list or &#39;auto&#39;</td>
<td>&#39;auto&#39;</td>
</tr>
<tr>
<td>shapes</td>
<td>single, list or &#39;auto&#39;</td>
<td>&#39;auto&#39;</td>
</tr>
</tbody></table>
<h2 id='data'>Data</h2>
<p>The data() command is provided to allow data ingestion from a variety of formats, and to give the user access to unique deep learning datasets. In addition to allowing access to Autonomio datasets, the function also supports importing from csv, json, and excel. The data importing function is for most cases.</p>
<pre class="highlight python tab-python"><code><span class="c"># loading 'random_tweets' dataset in to a dataframe</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="s">'random_tweets'</span><span class="p">)</span>

<span class="c"># loading data.csv in to a dataframe</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="s">'data.csv'</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s">'file'</span><span class="p">)</span>
</code></pre><h3 id='supported-formats'>Supported Formats</h3>
<ul>
<li>csv </li>
<li>txt</li>
<li>json</li>
<li>msgpack (highly compressed binary format)</li>
</ul>
<h3 id='example-datasets'>Example datasets</h3>
<p>Several unique deep learning focused datasets are provided with Autonomio. These datasets have not been released anywhere else, and relate to current affairs such as Twitter bots, ad fraud, US Election 2016, and party politics. </p>

<ul>
<li>election_in_twitter</li>
<li>programmatic_ad_fraund</li>
<li>parties_and_employment</li>
<li>tweet_sentiment</li>
<li>random_tweets</li>
<li>sites_category_and_vec</li>
</ul>

<blockquote>
<p>Dataset consisting of 10 minute samples of 80 million tweets</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'election_in_twitter'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>4,000 ad funded websites with word vectors and 5 categories</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'sites_category_and_vec'</span><span class="p">)</span>   
</code></pre>
<blockquote>
<p>Data from both buy and sell side and over 10 other sources</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'programmatic_ad_fraud'</span><span class="p">)</span>    
</code></pre>
<blockquote>
<p>9 years of monthly poll and unemployment numbers</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'parties_and_employment'</span><span class="p">)</span>   
</code></pre>
<blockquote>
<p>120,000 tweets with sentiment classification from NLTK</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'tweet_sentiment'</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>20,000 random tweets</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">data</span><span class="p">(</span><span class="s">'random_tweets'</span><span class="p">)</span>            
</code></pre><h3 id='query-parameters'>Query Parameters</h3>
<table><thead>
<tr>
<th>ARGUMENT</th>
<th>REQUIRED INPUT</th>
<th>DEFAULT</th>
</tr>
</thead><tbody>
<tr>
<td>name</td>
<td>dataset or filename</td>
<td>NA</td>
</tr>
<tr>
<td>mode</td>
<td>string (&#39;file&#39;)</td>
<td>&#39;default&#39;</td>
</tr>
<tr>
<td>sep</td>
<td>string e.g &#39;</td>
<td>&#39;</td>
</tr>
<tr>
<td>delimiter</td>
<td>string e.g &#39;,&#39;</td>
<td>None</td>
</tr>
<tr>
<td>header</td>
<td>string (&#39;file&#39;)</td>
<td>&#39;infer&#39;</td>
</tr>
</tbody></table>

<p><strong>name</strong> = Name of the dataset or file. In the case of file, should be csv/txt for comma etc. separated values, json for json file and msgpack for msgpack. Automation of handling the request will not work unless the filename </p>

<p><strong>mode</strong> = Either &#39;default&#39; which implies one of the Autonomio datasets, or &#39;file&#39; which is for loading a file. </p>

<p><strong>sep</strong> =  By default &#39;,&#39; but can be any string. </p>

<p><strong>delimiter</strong> =  This is used as secondary for separator (sep). Should be string, for example &#39;,&#39; when thousand separators are used.</p>

<p><strong>header</strong> =  Either integer for row number, &#39;None&#39; for no header or default &#39;infer&#39; will automatically decide (takes the top row mostly).</p>

<aside class="success">
Most important thing to remember is to be nice and have fun! :) 
</aside>
<h1 id='examples'>Examples</h1>
<p>Autonomio is very easy to use and it&#39;s straightforward to memorize the namespace which is just 4 commands and less than 40 arguments combined. Namespace memorization is one of the key differences between advanced and beginner users. Whereas Autonomio helps lower skill level practitioners to dramatically improve their capability, advanced practitioners enjoy significant productivity gains and headache reduction.</p>
<h2 id='prepare-and-train'>Prepare and Train</h2>
<p>A typical use-case, even with messy datasets with many columns, involves few lines of code and seconds or minutes of training time on a regular laptop machine.</p>

<blockquote>
<p>Medicare Provider Utilization and Payment Data</p>
</blockquote>
<pre class="highlight python tab-python"><code>
<span class="c"># do the python imports </span>
<span class="kn">from</span> <span class="nn">autonomio.commands</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">wrangler</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">predictor</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c"># import the data from csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="s">'medicare_10k.csv'</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'file'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">wrangler</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="s">'z'</span><span class="p">)</span>

<span class="c"># train a neural net</span>
<span class="n">train</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">17</span><span class="p">],</span><span class="s">'z'</span><span class="p">,</span><span class="n">df</span><span class="p">,</span><span class="n">epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s">'logcosh'</span><span class="p">,</span><span class="n">flatten</span><span class="o">=</span><span class="s">'median'</span><span class="p">)</span>
</code></pre>
<aside class="success">
See more examples throughout this user documentation. 
</aside>
<h1 id='shapes'>Shapes</h1>
<p>Shapes are used as part of the train() command, in order to dramatically change the network dimensions and shape with a single parameter. There are two parameters that work together to make up the shape and total neuron count of the neural network. </p>

<ul>
<li>shape</li>
<li>neuron_max </li>
</ul>

<blockquote>
<p>Examples: </p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="c"># produce a long_funnel where the highest neuron per layer is 10 </span>
<span class="n">train</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">df</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'long_funnel'</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c"># produce a brick where the highest neuron per layer is 55 </span>
<span class="n">train</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">df</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'brick'</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">55</span><span class="p">)</span>

</code></pre>
<p>NOTE: Shapes function is called from within the train() and does not serve a meaningful purpose for using separately. The function outputs a list with the neuron counts. </p>
<h2 id='funnel'>Funnel</h2><pre class="highlight plaintext"><code>\          /
 \        /
  \      /
   \    /
    |  |
</code></pre>
<p>Funnel is the shape, which is set by default. It roughly looks like an upside-dowm pyramind, so that the first layer is defined as neuron_max, and the next layers are sligtly decreased compared to previous ones.</p>

<p>As funnel shape is set by default, we do not need to input anything to use it.</p>

<blockquote>
<p>Example input (default setting):</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">tr</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre>
<p>For a five layer neural net, this will yield 10, 5, 3, 2, 1 neurons respectively. </p>
<h2 id='long-funnel'>Long Funnel</h2><pre class="highlight plaintext"><code> |          |
 |          |
 |          |
  \        /
   \      /
    \    /
     |  |
</code></pre>
<p>Long Funnel shape can be applied by defining shape as &#39;long_funnel&#39;. First half of the layers have the value of neuron_max, and then they have the shape similar to Funnel shape - decreasing to the last layer.</p>

<blockquote>
<p>Example input:</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">tr</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre>
<p>For a six layer neural net, this will yield 10, 10, 10, 5, 3, 2 neurons respectively. </p>
<h2 id='rhombus'>Rhombus</h2><pre class="highlight plaintext"><code>     /   \
    /     \
   /       \
  /         \
  \         /
   \       /
    \     /
     \   /
     |   |
</code></pre>
<p>Rhobmus can be called by definind shape as &#39;rhombus&#39;. The first layer equals to 1 and the next layers slightly increase till the middle one which equals to the value of neuron_max. Next layers are the previous ones goin in the reversed order. </p>

<blockquote>
<p>Example input:</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'rhombus'</span><span class="p">)</span>
</code></pre>
<p>For a five layer neural net, this will yield 1, 6, 10, 6, 1 neurons respectively. </p>
<h2 id='diamond'>Diamond</h2><pre class="highlight plaintext"><code>   /       \
  /         \
  \         /
   \       /
    \     /
     \   /
     |   |
</code></pre>
<p>Defining shape as &#39;diamond&#39; we will obtain the shape of the &#39;opened rhombus&#39;, where everything is similar to the Rhombus shape, but layers start from the larger number instead of 1. </p>

<blockquote>
<p>Example input: </p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'diamond'</span><span class="p">)</span>
</code></pre>
<p>For a six layer neural net, this will yield 6, 6, 10, 5, 3, 2 neurons respectively. </p>
<h2 id='hexagon'>Hexagon</h2><pre class="highlight plaintext"><code>    /    \
   /      \
  /        \
 |          |
 |          |
 |          |
  \        /
   \      /
    \    /
     |  |
</code></pre>
<p>Hexagon, which we get by calling &#39;hexagon&#39; for shape, starts with 1 as the first layer and increases till the neuron_max value. Then some next layers will have maximum value untill it starts to decrease till the last layer. </p>

<blockquote>
<p>Example input:</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'hexagon'</span><span class="p">)</span>
</code></pre>
<p>Output list of neurons(excluding ounput layer). </p>

<p>For a seven layer neural net, this will yield 1, 3, 5, 10, 10, 5, 3 neurons respectively.</p>
<h2 id='brick'>Brick</h2><pre class="highlight plaintext"><code>   |             |
   |             |
   |             |
   |             |
    ----     ----
        |   |

</code></pre>
<p>All the layers have neuron_max value. Called by shape=&#39;brick&#39;. </p>

<blockquote>
<p>Example input:</p>
</blockquote>
<pre class="highlight python tab-python"><code>    <span class="n">tr</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'brick'</span><span class="p">)</span>
</code></pre>
<p>Output list of neurons(excluding ounput layer). </p>

<p>For a five layer neural net, this will yield 10, 10, 10, 10, 10 neurons respectively.</p>
<h2 id='triangle'>Triangle</h2><pre class="highlight plaintext"><code>        /    \
       /      \
      /        \
     /          \
    /            \
    ----      ----
        |    |
</code></pre>
<p>This shape, which is called by defining shape as &#39;triangle&#39; starts with 1 and increases till the last input layer, which is neuron_max. </p>

<blockquote>
<p>Example input: </p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'triangle'</span><span class="p">)</span>
</code></pre>
<p>Output list of neurons(excluding ounput layer). </p>

<p>For a five layer neural net, this will yield 1, 2, 3, 5, 10 neurons respectively.</p>
<h2 id='stairs'>Stairs</h2><pre class="highlight plaintext"><code>   |                      |
    ---                ---
       |             |
        ---       ---
           |     |
</code></pre>
<p>You can apply it defining shape as &#39;stairs&#39;. If number of layers more than four, then each two layers will have the same value, then it decreases.If the number of layers is smaller than four, then the value decreases every single layer. </p>

<blockquote>
<p>Example input: </p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="s">'neg'</span><span class="p">,</span><span class="n">temp</span><span class="p">,</span><span class="n">layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">neuron_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="s">'stairs'</span><span class="p">)</span>
</code></pre>
<p>For a six layer neural net, this will yield 10, 10, 8, 8, 6, 6 neurons respectively.</p>
<h1 id='language-processing'>Language Processing</h1><h2 id='unstructed-data'>Unstructed Data</h2>
<p>By some estimates, more than 90% of meaningful data is unstructured. Ingestion of unstructured data with Autonomio could not be easier; inputting unstructured data as &#39;x&#39; is handled automatically whereas the input is converted in to word2vec word vectors. The way this works is roughly:</p>

<p>1) detect if a single column of x features is text
2) use spaCy NLP to vectorize the text 
3) create 300 invididual features/columns from the vector
4) use the 300 features as signals for training the model </p>

<p>In addition to doing this automatically with train() having a single x column with text, when one or more columns of text needs to be vectorized as part of a dataset with other features, this can be done easily by using the &#39;vectorize&#39; parameter in train().</p>

<p>Also the wrangler() data preparation function can be used to vectorize unstructured features (e.g. tweets or names).</p>
<h2 id='language-support'>Language support</h2>
<p>Autonomio&#39;s vectorizing engine spaCy supports currently 13 languages: </p>

<ul>
<li>English</li>
<li>German</li>
<li>Chinese</li>
<li>Spanish</li>
<li>Italian</li>
<li>French</li>
<li>Portuguese</li>
<li>Dutch</li>
<li>Swedish</li>
<li>Finnish</li>
<li>Hungarian</li>
<li>Bengali</li>
<li>Hebrew</li>
</ul>

<p>NOTE: the spacy language libraries have to be downloaded each separately.</p>

<p><a href="https://spacy.io/docs/api/language-models">Read spaCy&#39;s language page</a></p>
<h2 id='adding-new-languages'>Adding new languages</h2>
<p>spaCy makes it reletively streamlined to create support for any language and the challenge can (and should be) approached iteratively. </p>

      </div>
      <div class="dark-box">
          <div class="lang-selector">
                <a href="#" data-language-name="python">python</a>
          </div>
      </div>
    </div>
  </body>
</html>
